<!-- #region -->
## 评价指标总结

- 评价指标定义
    - 损失函数（loss）：用来表示预测（y）与已知答案（y_）的差距。在训练神经网络时，通过不断改变神经网络中所有参数，使损失函数不断减小，从而训练出更高准确率的神经网络模型。**是定义在单个样本上的，是指一个样本的误差。**
    - 代价函数和损失函数 相似，**只不过代价函数的结果不会用于训练过程中**。是定义在整个训练集上的，是所有样本误差的平均，
也就是所有损失函数值的平均。
    - 目标函数是一个相关但更广的概念，针对的是经验风险以及结构风险最小化，一般目标函数就是加了正则项的损失函数。



- 模型对未知数据的预测能力称为模型的泛化能力，它是模型最重要的性质。
    - 只有选择与问题相匹配的评估方法，才能快速地发现模型选择或训练过程中出现的问题，迭代地对模型进行优化。
    - 可以分为分类问题、回归问题、序列预测和翻译问题往往需要使用不同的指标进行评估。
<!-- #endregion -->

### 分类问题
- 一般包括，准确率、精确率、召回率等

| 指标名称 | 指标定义 | 指标应用场景 | 指标缺点
| :- |:- |:- |:-
| 准确率 | accuracy，指分类正确的样本占总样本个数的比例（这个没说是正样本哦） |  | 当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素
| 精准率 | precision，指分类正确的正样本个数占分类器预测为正样本的样本个数的比例 | 取伪代价（负样本预测成正样本）很大时，使用本指标 | 只预测了1个正样本，且预测对了，则精准率满了
| 召回率 | recall，指分类正确的正样本个数占实际的正样本个数的比例 | 弃真代价（正样本预测成负样本）很大时，使用本指标 | 将所有样本都预测为正样本，则召回率满啦，**覆盖正样本的比例**
| F1得分 | 是精确率和召回率的调和平均数，综合反应模型分类的性能， $\frac{1}{F1} = \frac{1}{2}(\frac{1}{precision} + \frac{1}{recall})$ | 分类场景下，应用的比较多 | 
| [ROC曲线](#ROC曲线) | ROC曲线的横坐标为假阳性率（False Positive Rate，FPR）；纵坐标为真阳性 率（True Positive Rate，TPR） | 经常作为评估二分类器最重要的指标之一
| binary_crossentropy | 交叉熵计算公式： $H(y, \overline{y}) = -\sum_{i=1}^n(\overline{y_i} * logy_i)$，<br> 表示两个概率分布之间的距离，交叉熵越大，两个概率分布距离越远，两个概率分布越相异；交叉熵越小，两个概率分布距离越近，两个概率分布越相似  |  分类任务
| squared_hinge | 平方铰链损失函数，取1减去预测值与实际值乘积的结果与0比相对大的值的平方的累加均值。<br> 公式为： $\frac{\sum_{i=1}^n(max(0, 1 - y_i\hat{y_i}))^2}{n}$ | 作为SVM的目标函数
| hinge | 铰链损失函数，取1减去预测值与实际值乘积的结果与0比相对大的值的的累加均值。<br> 公式为： $\frac{\sum_{i=1}^n(max(0, 1 - y_i\hat{y_i}))}{n}$ | 

<!-- #region -->
#### ROC曲线
- 定义
    - ROC曲线则有很多优点，经常作为评估二 值分类器最重要的指标之一。
    - ROC曲线的横坐标为假阳性率（False Positive Rate，FPR）；纵坐标为真阳性 率（True Positive Rate，TPR）
  
  
- 公式说明
    - P为真实的正样本的数量；N为真实的负样本的数量；TP为正样本中被预测为正样本的数量；FP为负样本中被预测为正样本的数量
        - 横坐标，假阳性率  $FPR = \frac{FP}{N} $
        - 纵坐标，真阳性率  $TPR = \frac{TP}{P} $
<!-- #endregion -->

<!-- #region -->
### 回归问题
    

| 指标名称 | 指标定义 | 指标应用场景 | 指标优缺点
| :- | :-: |:- |:- 
| RMSE | 均方根误差，反映回归模型预测值与真实值的偏离程度，<br>公式为： $\displaystyle RMSE(y, \hat{y}) = \sqrt{\frac{\sum_{i=1}^n(y_i-\hat{y_i})^2}{n}}$  | 回归任务| 受异常值影响较大，如果存在个别偏离程度非常大的离群点（Outlier）时，即使离群点 数量非常少，也会让RMSE指标变得很差
| MAPE | 平均绝对百分比误差，累加的是（预测值与实际值的差）除以（实际值)，然后求均值。 <br>公式为： $\displaystyle MAPE = \sum_{i=1}^n(\|\frac{(y_i - \hat{y_i})}{y_i}\|) * 100 / n$ | 回归任务 | 相比RMSE，MAPE相当于把每个点的误差进行了归一化，降低了个别离群点带来的绝对误差的影响
| MSE | 均方误差，公式为： $\displaystyle MSE = \frac{\sum_{i=1}^n(y_i-\hat{y_i})^2}{n}$ | 回归任务
| MAE | 绝对值均差，公式为： $\displaystyle MAE = \frac{\sum_{i=1}^n(\|y_i-\hat{y_i}\|)}{n}$ |  回归任务
| MSLE | 均方对数误差，加入了log对数，对预测值与实际值之后，然后取对数，作差，平方，累加求均值。<br>公式为： $\displaystyle MSLE = \frac{\sum_{i=1}^n(\log y_i- \log \hat{y_i})^2}{n}$  | 回归任务 | 当预测值出现较大差异时,它具有放松惩罚效果的效果
<!-- #endregion -->

### 翻译问题

- 如果翻译系统越接近人工翻译结果，那么它的翻译质量就越高，评测关键就在于如何定义系统译文与参考译文之间的相似度。

| 指标名称 | 指标定义 | 指标应用场景 | 指标优缺点
| :- | :- |:- |:- 
| [BLEU指标](#BLEU指标) | BLEU采用的方式是比较并统计共现的n元词的个数，**即统计同时出现在系统译文（模型推理）和参考译文（标准答案）中的n元词的个数，最后把匹配到的n元词的数目除以系统译文（模型推理）的单词数目，得到评测结果。** | 翻译问题，短文本场景 | BLEU是目前最接近人类评分的<br> 缺点：短译句的测评精度有时会较高
| [ROUGH指标](#ROUGH指标) | ROUGH算法基本思路和BLEU差不多，不过它统计的是**召回率**，也就是对于标准译文中的短语，统计一下它们有多少个出现在机器翻译的译文当中，其实就是看**机器翻译有多少个翻译对了**，这个评价指标主要在于标准译文中的短语都出现过，那么自然机器翻译的译文越长结果越好。| 翻译问题 | 机器翻译的译文越长结果越好<br>缺点：没有考虑语义层次上的匹配；
| METOR | 翻译模型翻译的结果是对的，只是碰巧跟参考译文没对上（比如用了一个同义词），于是用WordNet等知识源扩充了一下同义词集，同时考虑了单词的词形，最后还有召回率和准确率两者都要考虑，用F值作为最后的评价指标。| 翻译问题 | 使用较少，需要有外部知识源（WordNet 等）来进行单词对齐
| CIDEr | CIDEr是**BLEU和向量空间模型的结合**。它把每个句子看成文档，然后计算TF-IDF向量（只不过term是n-gram而不是单词）的余弦夹角，据此得到候选句子和参考句子的相似度，同样是不同长度的n-gram相似度取平均得到最终结果。| 翻译问题

<!-- #region -->
#### BLEU指标
- 内容介绍
    - **即统计同时出现在系统译文（模型推理）和参考译文（标准答案）中的n元词的个数，最后把匹配到的n元词的数目除以系统译文（模型预测）的单词数目，得到评测结果。**
    - 1. **一般n=2，即比较1个词、2个词**来计算
    - 2. 提出取机器翻译译文（模型推理）N-gram的出现次数和参考译文中N-gram最大出现次数中的最小值的算法
    - 3. 针对翻译译文长度比参考译文要短的情况，就需要一个惩罚的机制去控制


- 优缺点
    - 1、不考虑语言表达（语法）上的准确性；
    - 2、测评精度会受常用词的干扰；
    - 3、短译句的测评精度有时会较高；
    - 4、没有考虑同义词或相似表达的情况，可能会导致合理翻译被否定；
    
    
- 指标计算demo
![评价指标_BLEU](https://cdn.jsdelivr.net/gh/w666x/image/NLP_base/评价指标_BLEU.jpg)
<!-- #endregion -->

<!-- #region -->
#### ROUGH指标
- 内容介绍
    - ROUGH算法基本思路和BLEU差不多，不过它统计的是召回率，也就是对于标准译文中的短语，统计一下它们有多少个出现在机器翻译的译文当中，其实就是看机器翻译有多少个翻译对了，
    - 除数的分母，是标准译文（标准答案）中的短语的个数
    - **这个评价指标主要在于标准译文中的短语都出现过，那么自然机器翻译的译文越长结果越好。**
    - lcs，指的是最长公共子串（Longest Common Subsequence）
    - 对于Rouge-S而言，分母是$C_N^2$的形式，N为文本的长度
    


- 优缺点
    - 缺点是死板，不够灵活，没有考虑语义层次上的匹配。
    - 可以考虑用word embedding来做语义层次上的评判，而不仅仅是n-gram的匹配。
    

![评价指标_ROUGE](https://cdn.jsdelivr.net/gh/w666x/image/NLP_base/评价指标_ROUGE.jpg)
<!-- #endregion -->

### 其他指标


#### 方差和偏差

- 方差和偏差对比

| 指标名称 | 指标定义  | 说明
|:-  |:- |:-
| 偏差 | 描述的是预测值（估计值）的**期望**与真实值之间的差距。| 偏差越大，预测值越偏离真实数据。
| 方差 | 描述的是预测值的变化范围，离散程度，也就是预测值离其自己期望值的距离。 | 方差越大，数据的分布越分散


## 模型初始化


### 深度学习

<!-- #region -->
#### 参数初始化

- 参数初始化
    - 参数初始值的选取十分关键，关系到网络的优化效率和泛化能力。
    - 一般而言，参数初始化的区间应该根据神经元的性质进行差异化的设置。
        - 如果一个神经元的输入连接很多，它的每个输入连接上的权重就应该小一些，以避免神经元的输出过大（当激活函数为 ReLU 时）或过饱和（当激活函数为Sigmoid函数时）。
    - 初始化的方法
        - 预训练初始化：通常情况下，一个已经在大规模数据上训练过的模型可以提供一个好的参数初始值，这种初始化方法称为预训练初始化。
        - 随机初始化：使得不同神经元之间的区分性更好。
    - 如何选取合适的随机初始化区间？
        - $\color{red}{为了使得训练平稳性，应当尽量保持每个神经元的输入和输出的方差一致}$


##### 参数初始化概览

- 概览
    - 用的比较多的一般就，**[Kaiming初始化](#Kaiming初始化)、[结合Batch Normalization的随机初始化](#batch随机)、[预训练初始化](#pre-training)（迁移学习啦）**

|初始化方法 | 方法说明 | 效果 | 应用场景 | 可能出现的问题
|:- |:- |:- |:- | :-
|常用启发式 | 根据[-1,1]中的均匀分布来初始化权重，然后按 $\sqrt{(\frac{1}{n})}$的比例缩放 | 会导致网络较低层(较高)的权值梯度与最上层(接近于零)的权值梯度之间的差异更大。 | 应用于关于零对称且在[-1,1]内有输出的激活函数softsign和tanh等激活函数时 | 使用“标准”权重初始化方法重新运行我们的100层tanh网络会导致激活梯度变得无限小
|[Xavier初始化](#Xavier初始化)(正则初始化) | **Xavier初始化将每层权重设置为在有界的随机均匀分布中选择的值**： $\pm\frac{\sqrt{6}}{\sqrt{n_i + n_{i+1}}}$，其中nᵢ是该层的传入网络连接数或该层的“fan-in”，nᵢ₊1是该层的传出网络连接数，也称为fan-out | Xavier权重初始化将保持激活函数和反向传播梯度的方差，一直向上或向下传播到神经网络的每一层。 | 应用于关于零对称且在[-1,1]内有输出的激活函数softsign和tanh等激活函数时  | 当他们使用ReLU训练更深层的网络时。何凯明等人发现使用Xavier初始化的30层CNN完全停止并且不再学习
|xavier normal init | 使用高斯分布初始化 $\pm\frac{2}{\sqrt{(n_i + n_{i+1})}}$ | xavier系列对tanh等激活函数都work，但是对ReLU效果不好，它是基于线性关系推导出的
|Kaiming初始化 <b id="Kaiming初始化"></b> | 使用适合给定图层的权重矩阵创建张量，并使用从标准正态分布中随机选择的数字填充它、，然后按$\sqrt{\frac{2}{n}}$的比例缩放 |包含ReLU激活函数，并且是深度的。在这种情况下，Kaiming初始化应该是我们的首选权重初始化策略。 | 处理这些非对称，非线性激活的深层神经网络的比如relu激活函数 | 
|constant init | 使用指定常数初始化 |不建议使用 | | 使用常数初始化，对于梯度，连乘操作很容易造成梯度消失或者梯度爆炸。
|zeros init | 使用零矩阵初始化 |不建议使用 | | 使用零初始化，神经网络学习到的东西都是一样的，因为梯度相同。
|ones init | 使用一矩阵初始化 |不建议使用 | | 都不能保证输入和输出方差保持一致的特性
|identity init | 使用单位矩阵初始化 |不建议使用 | | 
|orthogonal init | 使用正交矩阵初始化，对于矩阵（如果是张量，按最后一维reshape成矩阵），使用随机初始化的正态分布矩阵进行QR，使用Q矩阵来初始化。 | 正交初始化可以使得卷积核更加紧凑，可以去除相关性，使模型更容易学到有效的参数。
|random normal init | 使用随机正态分布 | | tensorflow中，默认初始化为均值为0，方差为1的正态分布。
|random uniform init | 使用随机均匀分布 | | tensorflow中，对于float型变量，默认初始化为[0,1]
|truncated normal init | 截断正态分布将随机变量界定一一个确定的范围内(a,b)
|he_normal init | 使用高斯分布初始化，参数如下 $N(0, \sqrt{\frac{2}{n_{in}})}$ | | he系列的方式针对的是ReLU激活函数，保证了ReLU函数的有效性
|he_uniform init| 使用均匀分布初始化，参数如下 $N(-\sqrt{\frac{6}{n_{in}}}, \sqrt{(\frac{6}{n_{in}}))}$ | | he系列的方式针对的是ReLU激活函数，保证了ReLU函数的有效性
|lecun normal init | 使用高斯分布初始化，参数如下 $N(0, \sqrt{\frac{1}{n_{in}})}$  |
|lecun uniform init| 使用均匀分布初始化，参数如下 $N(-\sqrt{\frac{3}{n_{in}}}, \sqrt{\frac{3}{n_{in}})}$



##### 参数初始化详解

- 1.全零初始化
    - 我们在**线性回归，logistics回归的时候，基本上都是把参数初始化为0**，我们的模型也能够很好的工作。
    - 然后在神经网络中，把参数初始化为0是不可以的。这是因为如果把参数初始化0，那么每一层的神经元学到的东西都是一样的（输出是一样的），而且在BP的时候，每一层内的神经元也是相同的，因为他们的gradient相同，weight update也相同。这显然是一个不可接受的结果。



- 2.随机初始化
    - 随机初始化是很多人经常使用的方法，**一般初始化的权重为高斯或均匀分布中随机抽取的值**。
    - 然而这是有弊端的，一旦随机分布选择不当，就会导致网络优化陷入困境。



- 3.Xavier初始化 <b id="Xavier初始化"></b>
    - **Xavier初始化可以帮助减少梯度消失的问题**，使得信号在神经网络中可以传递得更深，在经过多层神经元后保持在合理的范围（不至于太小或太大）。
    - Xavier初始化的基本思想：保持输入和输出的方差一致（服从相同的分布），这样就避免了所有输出值都趋向于0。
    - 注意，为了问题的简便，Xavier初始化的推导过程是基于线性函数的（假设激活函数是线性的）。
    - **未考虑激活函数对输出数据分布的影响啦**
    - 在神经网络中，第l层的一个神经元为 $a^{(l)}$,接收到前一层的 $M_{l-1}$个神经元的输出 $a_i^{l-1}$，这里的激活函数f(.)为恒等函数：
        $$a^{l} = f(\sum_{i=1}^{M_{l-1}}w_i^{(l)}a_i^{(l-1)})$$
        - $\alpha^{(l)}$的方差为（假设w,a的均值为0，且独立地服从同样的分布， $E(w_i^{(l)})和E(a_i^{(l-1)})$都为0，那么上式表达为：

$$\begin{aligned} var(a^{(l)}) &= var(\sum_{i=1}^{M_{l-1}}w_i^{(l)}a_i^{(l-1)}) \\
&= \sum_{i=1}^{M_{l-1}}(E(w_i^{(l)}))^2var(a_i^{(l-1)}) + E(a_i^{(l-1)})^2var(w_i^{(l)}) + var(a_i^{(l-1)})var(w_i^{(l)}) \\
&= \sum_{i=1}^{M_{l-1}}var(w_i^{(l)})var(a_i^{(l-1)}))  \text{同一层神经元同方差，所以可以将求和符号等价成 $M_{l-1}$了} \\
&= M_{l-1}var(w_i^{(l)})var(a_i^{(l-1)})) 
\end{aligned}$$  

- 接上表达式
    - 要保持每个神经元的输入 $var(a^{(l)})$和输出的方差 $var(a_i^{(l-1)}))$一致，则需要 $M_{l-1}var(w_i^{(l)}) == 1$    
        - 需要令 $var(w_i^{(l)}) = \frac{1}{M_{l-1}}$，考虑到在反向传播过程中，误差信号也不被放大或者缩小，
        - 所以令 $var(w_i^{(l)}) = \frac{1}{M_{l}}$，
        - 综合两者，即有 $var(w_i^{(l)}) = \frac{2}{M_{l-1} + M_l}$
    - 注：这里假设激活函数为恒等函数，但是 也适用于 Logistic 函数和Tanh 函数。
    - 因为神经元的参数和输入的绝对值通常比较小，处于激活函数的线性区间，这时Logistic函数和Tanh函数可以近似为线性函数。在实际应用中，**通常乘以一个缩放因子 $\rho$**


- 4.He initialization（MSRA）
    - 为了解决上面的问题，何恺明大神提出了一种针对ReLU的初始化方法，一般称作He
    - 思想是：**在ReLU网络中，假定每一层有一半的神经元被激活，另一半为0（x负半轴中是不激活的），所以要保持variance不变，只需要在Xavier的基础上再除以2**
    - 效果是比Xavier initialization好很多。现在神经网络中，隐藏层常使用ReLU，权重初始化常用He initialization这种方法。


- 5.Batch Normalization Layer <b id="batch随机"></b>
    - 在网络中间层中使用Batch Normalization层一定程度上能够减缓对较好的网络参数初始化的依赖，使用方差较小的参数分布即可。


- 6.pre-training<b id="pre-training"></b>
    - 在迁移学习的情况下，优先采用预训练的模型进行参数初始化。
<!-- #endregion -->

#### 常见优化方法


##### 总结概览

|学习率调整方法 | 方法说明 | 效果
|:- |:- |:- 
| [SGD](#SGD) | 随机梯度下降，随机也就是说我们用样本中的一个例子来近似所有的样本，来调整 $\theta$ | 不稳定，可能很难收敛
| BGD | 批梯度下降，一次迭代是对所有样本进行计算，由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。当目标函数为凸函数时，BGD一定能够得到全局最优。 | 当样本数目 m 很大时，每迭代一步都需要对所有样本计算，训练过程会很慢。
| MBGD | 小批量梯度下降，次迭代 使用 **batch_size** 个样本来对参数进行更新。| 每次使用一个batch可以大大减小收敛所需要的迭代次数，同时可以使收敛到的结果更加接近梯度下降的效果。

<!-- #region -->
##### 梯度下降算法
- 深度神经网络的参数学习主要通过**梯度下降法**来寻找一组可以最小化结构风险的参数。
- 在具体实现中，梯度下降法可以分为：
    - 批量梯度下降（速度慢，稳定）
    - 随机梯度下降（速度快，不稳定）
    - 小批量梯度下降。
- 基于速度与稳定性的考量，经常使用小批量梯度下降法。


- 如何选择批量大小？
- 一般而言，批量大小会影响随机梯度的方差（即稳定性）。
    - 批量越大，随机梯度的方差越小，引入的噪声也越小，训练也越稳定，相应地，可以设置较大的学习率。
    - 批量较小时，需要设置较小的学习率，否则会影响模型收敛。
    - 学习率通常要随着批量大小的增大而相应地增大。 
    - 线性缩放规则：当批量大小增加m倍时，学习率也增加m倍


![梯度下降算法的简单证明](https://cdn.jsdelivr.net/gh/w666x/image/NLP_base/梯度下降算法简单证明.jpg)


- （1）<b id="SGD">随机梯度下降</b>(SGD)，Stochastic Gradient Descent
    - 在每次更新时用1个样本，可以看到多了随机两个字，随机也就是说我们用样本中的一个例子来近似所有的样本，来调整$\theta$，因而随机梯度下降是会带来一定的问题。
    - 频繁的更新使得参数间具有高方差，损失函数会以不同的强度波动。
    - 但SGD的问题是，**由于频繁的更新和波动，最终将收敛到最小限度，很难收敛，可能无法获得给出损失函数的最小值**。
<!-- #endregion -->

##### 学习率调整

|学习率调整方法 | 方法说明 | 效果
|:- |:- |:- 
| [AdaGrad](#AdaGrad算法) | 自适应梯度（Adaptive Gradient），对学习率进行调节，考虑历史梯度平方累积 | 解决普通的sgd方法中学习率一直不变的问题
| [RMSprop](#RMSProp算法) | 对学习率进行调节，考虑历史梯度平方加权累积 | 有些情况下可避免 AdaGrad 算法中学习率不断单调下降以至于过早衰减的缺点
| [AdaDelta](#AdaDelta算法) | 对学习率进行调节，考虑历史梯度平方加权累积以及历史更新梯度加权累积 |

<!-- #region -->
- 学习率调整
    - 在梯度下降法中，学习率$\alpha$的取值很关键，如果过大很可能不会收敛，如果过小则收敛速度太慢。
    - 学习率调整方法：
        - 学习率衰减
        - 学习率预热
        - 自适应调整学习：AdaGrad、RMSprop、AdaDelta
        
        
- 学习率衰减
    - 一开始可设置大点的学习率；在最优点附近后减小学习率
    - 比如可以设置，分段衰减、逆时衰减、指数衰减等
    
    
$$\begin{aligned} \alpha_t&=\alpha_0\frac{1}{1+\beta*t} \space \text{逆时衰减} \\
            \alpha_t&=\alpha_0\beta^t \space \text{指数衰减} \\ 
            \alpha_t&=\alpha_0\exp(-\beta*t) \space \text{自然指数衰减} \\ 
            \alpha_t&=0.5*\alpha_0(1+\cos(\frac{t\pi}{T})) \space \text{余弦衰减} \\ 
\end{aligned} \tag{衰减函数}$$
    
    
- 学习率预热
    - **为了提高训练稳定性，在最初几轮迭代时，采用比较小的学习率，**等梯度下降到一定程度后再恢复到初始的学习率
<!-- #endregion -->

<!-- #region -->
- $\color{red}{AdaGrad算法}$<b id="AdaGrad算法"></b>（Adaptive Gradient Algorithm）
    - 在一般的梯度下降法中，每个参数在每次迭代时都使用相同的学习率。但**实际上在每个参数的维度上收敛速度都不相同**
    - AdaGrad根据不同参数的收敛情况分别设置学习率:
        - 在第t次迭代时，先计算参数梯度平方的累计值； $G_t = \sum_{i=0}^Tg_i^2$
        - 参数更新差值 $\Delta\theta_t$为：( $g_t$表示第t次迭代计算出的梯度向量，包含各个参数对应的偏导数， $\epsilon$是一个常数，取值为 $[\exp(-10), \exp(-7)]$之间)：
        $$\Delta\theta_t = \theta_{t+1} - \theta_t = -\frac{\alpha}{\sqrt{G_t + \epsilon}}g_t$$

    - $\color{red}{优点}$学习率将随着梯度的倒数增长，也就是**说有较大梯度累积的具有较小的学习率，而较小的梯度累积的具有较大的学习率**，可以解决普通的sgd方法中学习率一直不变的问题。在数据分布稀疏的场景，能更好利用稀疏梯度的信息，比标准的SGD算法更有效地收敛
    - $\color{blue}{缺点}$由于分母中对历史梯度一直累加，**学习率将逐渐下降至0**，在经过一定次数的迭代依然没有找到最优点时，由于这时的学习率已经非常小，很难再继续找到最优点
    - 同SGD区别
        - 与SGD的核心区别在于计算更新步长时，增加了分母：**梯度平方累积和的平方根**。
        - 此项能够累积各个参数gt,i的历史梯度平方，频繁更新的梯度，则累积的分母项逐渐偏大，那么更新的步长(stepsize)相对就会变小，
        - 而稀疏的梯度，则导致累积的分母项中对应值比较小，那么更新的步长则相对比较大。


- $\color{red}{RMSProp算法}$<b id="RMSProp算法"></b>
    - RMSProp优化算法和AdaGrad算法唯一的不同，在于累积平方梯度Gt的求法不同，用一个衰减系数β(一般取0.9)来控制历史信息的获取。
    - 历史梯度信息的累计乘上一个衰减系数 $\beta$, 然后用 $(1-\beta)$作为当前梯度的平方加权系数相加
    $$G_t = \beta G_{t-1} + (1-\beta)g_t^2$$
    - 在迭代过程中，每个参数的学习率并不是呈衰减趋势，既可以变小也可以变大，在**有些情况下可避免 AdaGrad 算法中学习率不断单调下降以至于过早衰减的缺点**。
    - 在不稳定(Non-Stationary)的目标函数下，比基本的SGD、Momentum、AdaGrad表现更良好.
    
    
    
- $\color{red}{AdaDelta算法}$<b id="AdaDelta算法"></b>
    - 不仅对历史梯度信息做有选择的累加，对历史的参数更新差值 $\Delta\theta$也做有选择的累加
    $$\Delta X_{t-1} = \gamma\Delta X_{t-2} + (1-\gamma)\Delta\theta_{t-1}^2$$
    - 对于 $G_t$的运算和RMSProp一样
    - 参数更新差值 $\Delta\theta_t$为：
    $$\Delta\theta_t = -\frac{\sqrt{\Delta X_{t-1} + \epsilon}}{\sqrt{G_t + \epsilon}}g_t \text{在一定程度上保持了学习率的平稳性}$$
<!-- #endregion -->

##### 梯度修正

|梯度修正方法 | 方法说明 | 效果
|:- |:- |:- 
| [Momentum](#Momentum动量法) | 对梯度进行调节，考虑历史梯度累积 | 通过优化相关方向的训练和弱化无关方向的振荡，来加速SGD训练
| [Nesterov](#Nesterov加速梯度) | 对梯度进行调节，改进Momentum中的历史梯度累积 | 
| [Adam](#Adam算法)|  可以理解为是RMSprop+Momentum | **比较常用**

<!-- #region -->
- 梯度修正
    - 在梯度下降法中，除了学习率调整，还可以调整梯度。批量梯度下降法中，如果每次选取样本数量比较少，损失会呈现振荡的方式下降（与整体训练集上的最优梯度不一致）。
    - 解决方式：通过使用**最近一段时间内的平均梯度来代替当前时刻的随机梯度来作为参数更新的方向**，从而提高优化速度。
        - Momentum动量
        - Nesterov加速梯度
        - **Adam方法**
        
        
- <b id="Momentum动量法">Momentum动量法</b>
    - 是是模拟物理中的概念，某物体的动量指的是该物体在它运动方向上保持运动的趋势。动量法是会考虑之前的梯度情况的；
    - **更新取决于最近一段时间内梯度的加权平均值。当某个参数在最近一段时间内的梯度方向不一致时，参数更新幅度变小；反之，参数更新幅度变大，起到加速作用**
    - 参数更新差值为 $\Delta \theta_t$为（其中P通常设置为0.9）：
    
$$\Delta\theta_t = p\Delta\theta_{t-1} - \alpha g_t = -\alpha \sum_{i=1}^tp^{t-i}g_i$$

    
    
    
- <b id="Nesterov加速梯度">Nesterov加速梯度</b>
    - 是对Momentum动量法的改进，
    - 在动量法中，参数更新方向 $\Delta\theta_t$为，上一步的参数更新方向 $\Delta\theta_{t-1}$和当前梯度的反方向 $-g_t$的叠加。
    - 相当于分为两步进行，先根据 $\Delta\theta_{t-1}$更新一次得到参数 $\theta$，再用$-g_t$进行更新
        - 其中梯度 $g_t$为点 $\theta_{t-1}$上面的梯度，因此在第二步更新中有些不太合理，更合理的更新方向应该为 $\theta^{'}$上的梯度。
    
$$\theta^{'} = \theta_{t-1} + \rho \Delta\theta_{t-1} \\ \theta_t = \theta^{'} - \alpha g_t$$

    
    
    
- <b id="Adam算法">Adam算法</b>
    - 自适应时刻估计方法（Adaptive Moment Estimation），可以看作Momentum和 RMSprop 算法的结合，不但使用动量作为参数更新方向，而且可以自适应调整学习率
    
$$\begin{aligned} RMSprop：G_t&=\beta G_{t-1} + (1-\beta)g_t^2 \\
        Momentum：M_t&=\gamma M_{t-1} + (1-\gamma)g_t \\ 
     通常情况下，\beta = 0.9,\gamma=0.99, g_t为历史梯度
\end{aligned}$$

- 接上面的啦
    - 假设 $M_0=0, G_0=0$，那么在迭代初期 $M_t和G_t$的值会比真实的均值和方差要小，进行修正：
$$G^{'}_t = \frac{G_t}{1-\beta}, M^{'}_t = \frac{M_t}{1-\gamma}$$
    - 参数更新差值 $\Delta\theta_t$为：
$$\Delta\theta_t = -\frac{\alpha}{\sqrt{G^{'}_t + \epsilon}}M^{'}_t$$
    - 与其他自适应学习率算法相比，其收敛速度更快，学习效果更为有效，而且可以纠正其他优化技术中存在的问题，
        - 如学习率消失、收敛过慢或是高方差的参数更新导致损失函数波动较大等问题。
        - 对更新的步长计算，能够从梯度均值及梯度平方两个角度进行自适应地调节，而不是直接由当前梯度决定
<!-- #endregion -->
