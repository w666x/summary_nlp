<!-- #region -->
## 评价指标总结

- 评价指标定义
    - 损失函数（loss）：用来表示预测（y）与已知答案（y_）的差距。在训练神经网络时，通过不断改变神经网络中所有参数，使损失函数不断减小，从而训练出更高准确率的神经网络模型。**是定义在单个样本上的，是指一个样本的误差。**
    - 代价函数和损失函数 相似，**只不过代价函数的结果不会用于训练过程中**。是定义在整个训练集上的，是所有样本误差的平均，
也就是所有损失函数值的平均。
    - 目标函数是一个相关但更广的概念，针对的是经验风险以及结构风险最小化，一般目标函数就是加了正则项的损失函数。



- 模型对未知数据的预测能力称为模型的泛化能力，它是模型最重要的性质。
    - 只有选择与问题相匹配的评估方法，才能快速地发现模型选择或训练过程中出现的问题，迭代地对模型进行优化。
    - 可以分为分类问题、回归问题、序列预测和翻译问题往往需要使用不同的指标进行评估。
<!-- #endregion -->

### 分类问题
- 一般包括，准确率、精确率、召回率等

| 指标名称 | 指标定义 | 指标应用场景 | 指标缺点
| :- |:- |:- |:-
| 准确率 | accuracy，指分类正确的样本占总样本个数的比例（这个没说是正样本哦） |  | 当不同类别的样本比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素
| 精准率 | precision，指分类正确的正样本个数占分类器预测为正样本的样本个数的比例 | 取伪代价（负样本预测成正样本）很大时，使用本指标 | 只预测了1个正样本，且预测对了，则精准率满了
| 召回率 | recall，指分类正确的正样本个数占实际的正样本个数的比例 | 弃真代价（正样本预测成负样本）很大时，使用本指标 | 将所有样本都预测为正样本，则召回率满啦，**覆盖正样本的比例**
| F1得分 | 是精确率和召回率的调和平均数，综合反应模型分类的性能， $\frac{1}{F1} = \frac{1}{2}(\frac{1}{precision} + \frac{1}{recall})$ | 分类场景下，应用的比较多 | 
| [ROC曲线](#ROC曲线) | ROC曲线的横坐标为假阳性率（False Positive Rate，FPR）；纵坐标为真阳性 率（True Positive Rate，TPR） | 经常作为评估二分类器最重要的指标之一
| binary_crossentropy | 交叉熵计算公式： $H(y, \overline{y}) = -\sum_{i=1}^n(\overline{y_i} * logy_i)$，<br> 表示两个概率分布之间的距离，交叉熵越大，两个概率分布距离越远，两个概率分布越相异；交叉熵越小，两个概率分布距离越近，两个概率分布越相似  |  分类任务
| squared_hinge | 平方铰链损失函数，取1减去预测值与实际值乘积的结果与0比相对大的值的平方的累加均值。<br> 公式为： $\frac{\sum_{i=1}^n(max(0, 1 - y_i\hat{y_i}))^2}{n}$ | 作为SVM的目标函数
| hinge | 铰链损失函数，取1减去预测值与实际值乘积的结果与0比相对大的值的的累加均值。<br> 公式为： $\frac{\sum_{i=1}^n(max(0, 1 - y_i\hat{y_i}))}{n}$ | 

<!-- #region -->
#### ROC曲线
- 定义
    - ROC曲线则有很多优点，经常作为评估二 值分类器最重要的指标之一。
    - ROC曲线的横坐标为假阳性率（False Positive Rate，FPR）；纵坐标为真阳性 率（True Positive Rate，TPR）
  
  
- 公式说明
    - P为真实的正样本的数量；N为真实的负样本的数量；TP为正样本中被预测为正样本的数量；FP为负样本中被预测为正样本的数量
    $$\begin{aligned} 横坐标，假阳性率 FPR &= \frac{FP}{N} \\ 纵坐标，真阳性率 TPR &= \frac{TP}{P}  \end{aligned}$$
<!-- #endregion -->

<!-- #region -->
### 回归问题
    

| 指标名称 | 指标定义 | 指标应用场景 | 指标优缺点
| :- | :-: |:- |:- 
| RMSE | 均方根误差，反映回归模型预测值与真实值的偏离程度，<br>公式为： $\displaystyle RMSE(y, \hat{y}) = \sqrt{\frac{\sum_{i=1}^n(y_i-\hat{y_i})^2}{n}}$  | 回归任务| 受异常值影响较大，如果存在个别偏离程度非常大的离群点（Outlier）时，即使离群点 数量非常少，也会让RMSE指标变得很差
| MAPE | 平均绝对百分比误差，累加的是（预测值与实际值的差）除以（实际值)，然后求均值。 <br>公式为： $\displaystyle MAPE = \sum_{i=1}^n(\|\frac{(y_i - \hat{y_i})}{y_i}\|) * 100 / n$ | 回归任务 | 相比RMSE，MAPE相当于把每个点的误差进行了归一化，降低了个别离群点带来的绝对误差的影响
| MSE | 均方误差，公式为： $\displaystyle MSE(y, \overline{y}) = \frac{\sum_{i=1}^n(y_i-\overline{y_i})^2}{n}$ | 回归任务
| MAE | 绝对值均差，公式为： $\displaystyle MAE(y, \overline{y}) = \frac{\sum_{i=1}^n(\|y_i-\overline{y_i}\|)}{n}$ |  回归任务
| MSLE | 均方对数误差，加入了log对数，对预测值与实际值之后，然后取对数，作差，平方，累加求均值。<br>公式为： $\displaystyle MSLE(y, \overline{y}) = \frac{\sum_{i=1}^n(\log y_i- \log \overline{y_i})^2}{n}$  | 回归任务 | 当预测值出现较大差异时,它具有放松惩罚效果的效果
<!-- #endregion -->

### 翻译问题

- 如果翻译系统越接近人工翻译结果，那么它的翻译质量就越高，评测关键就在于如何定义系统译文与参考译文之间的相似度。

| 指标名称 | 指标定义 | 指标应用场景 | 指标优缺点
| :- | :- |:- |:- 
| [BLEU指标](#BLEU指标) | BLEU采用的方式是比较并统计共现的n元词的个数，**即统计同时出现在系统译文（模型预测）和参考译文（标准答案）中的n元词的个数，最后把匹配到的n元词的数目除以系统译文（模型预测）的单词数目，得到评测结果。** | 翻译问题 | 缺点：短译句的测评精度有时会较高
| ROUGH | ROUGH算法基本思路和BLEU差不多，不过它统计的是**召回率**，也就是对于标准译文中的短语，统计一下它们有多少个出现在机器翻译的译文当中，其实就是看**机器翻译有多少个翻译对了**，这个评价指标主要在于标准译文中的短语都出现过，那么自然机器翻译的译文越长结果越好。| 翻译问题
| METOR | 翻译模型翻译的结果是对的，只是碰巧跟参考译文没对上（比如用了一个同义词），于是用WordNet等知识源扩充了一下同义词集，同时考虑了单词的词形，最后还有召回率和准确率两者都要考虑，用F值作为最后的评价指标。| 翻译问题
| CIDEr | CIDEr是BLEU和向量空间模型的结合。它把每个句子看成文档，然后计算TF-IDF向量（只不过term是n-gram而不是单词）的余弦夹角，据此得到候选句子和参考句子的相似度，同样是不同长度的n-gram相似度取平均得到最终结果。| 翻译问题

<!-- #region -->
#### BLEU指标
- 内容介绍
    - **即统计同时出现在系统译文（模型预测）和参考译文（标准答案）中的n元词的个数，最后把匹配到的n元词的数目除以系统译文（模型预测）的单词数目，得到评测结果。**
    - **一般n=2，即比较1个词、2个词**来计算


- 优缺点
    - 1、不考虑语言表达（语法）上的准确性；
    - 2、测评精度会受常用词的干扰；
    - 3、短译句的测评精度有时会较高；
    - 4、没有考虑同义词或相似表达的情况，可能会导致合理翻译被否定；
    
    
- 指标计算demo
![评价指标_BLEU](https://cdn.jsdelivr.net/gh/w666x/image/NLP_base/评价指标_BLEU.jpg)
<!-- #endregion -->


![评价指标_ROUGE](https://cdn.jsdelivr.net/gh/w666x/image/NLP_base/评价指标_ROUGE.jpg)
