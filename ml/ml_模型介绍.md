## 模型介绍


### 线性回归模型

<!-- #region -->
#### 模型优缺点
- 优点：
    - 善于获取数据集中的线性关系；
    - 训练速度和预测速度较快；
    - 在小数据集上表现很好；
    - 结果可解释，并且易于说明；


- 缺点：
    - 不适用于非线性数据；
    - 预测精确度较低；
    - 可能会出现过拟合（下面的正则化模型可以抵消这个影响， Lasso回归, Ridge回归, Elastic-Net回归）；
    - 分离信号和噪声的效果不理想，在使用前需要去掉不相关的特征。
<!-- #endregion -->

### 逻辑回归


#### 相关内容
- 逻辑回归为啥不用mse
    - 因为用MSE作为二元分类的损失函数会有梯度消失的问题


### SVM

<!-- #region -->
#### 模型介绍
- SVM是一种二分类模型。它的基本思想是在**特征空间中寻找间隔最大化的分离超平面使得数据得到高效的二分类**，
    - 具体来讲，有三种情况
        - 当训练样本线性可分时，通过硬间隔最大化，学习一个线性分类器，即线性可分支持向量机；
        - 当训练样本近似线性可分时，引入松弛变量，通过软间隔最大化，学习一个线性分类器，即线性支持向量机；
        - 当训练样本线性不可分时，通过使用核函数和软间隔最大化，学习一个非线性支持向量机。
            - 当样本在原始空间线性不可分时，可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。


- 如何选择核函数
    - 当特征维数d超过样本数m时(文本分类问题通常是这种情况),使用线性核;
    - 当特征维数d比较小.样本数m中等时,使用RBF核;
    - 当特征维数d比较小.样本数m特别大时,支持向量机性能通常不如深度神经网络，所以，上神经网络吧
<!-- #endregion -->

<!-- #region -->
#### SVM如何用于多分类
- 一对多法
    - **训练时依次把某个类别的样本归为一类,其他剩余的样本归为另一类，这样k个类别的样本就构造出了k个SVM。**
    - 分类时将未知样本分类为具有最大分类函数值的那类。


- demo
    - 假如我有四类要划分（也就是4个Label），他们是A、B、C、D。于是我在抽取训练集的时候，分别抽取
        - （1）A所对应的向量作为正集，B，C，D所对应的向量作为负集；
        - （2）B所对应的向量作为正集，A，C，D所对应的向量作为负集；
        - （3）C所对应的向量作为正集，A，B，D所对应的向量作为负集；
        - （4）D所对应的向量作为正集，A，B，C所对应的向量作为负集；
    - 使用这四个训练集分别进行训练，然后的得到四个训练结果文件。在测试的时候，把对应的测试向量分别利用这四个训练结果文件进行测试。
    - 最后每个测试都有一个结果f1(x),f2(x),f3(x),f4(x)。
    - **于是最终的结果便是这四个值中最大的一个作为分类结果**。
    
    
- 一对一法（one-versus-one,简称OVO SVMs或者pairwise）
    - 其做法是在任意两类样本之间设计一个SVM，因此k个类别的样本就需要设计k(k-1)/2个SVM。
    - 当对一个未知样本进行分类时，最后得票最多的类别即为该未知样本的类别。


- 层次支持向量机
    - 首先将所有类别划分成两个子类，
    - 再将子类进一步划分成两个次级子类，如此循环下去，直到得到一个单独的子类为止，这样就得到一个倒立的二叉分类树。
<!-- #endregion -->
